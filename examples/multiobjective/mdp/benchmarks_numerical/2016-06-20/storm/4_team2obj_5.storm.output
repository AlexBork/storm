SToRM
---------------

Version: 0.9.1 (+1781 commits) build from revision g5578a73 (DIRTY).

Linked with GNU Linear Programming Kit v4.57.
Linked with SMT-RAT 2.1.0.
Linked with CARL.
Command line arguments: -s team/team2obj_5.nm -prop team/team2obj_5_numerical.pctl --precision 0.000001 --multiobjective:precision 0.0001 
Current working directory: /Users/tim/storm/examples/multi-objective/mdp

-------------------------------------------------------------- 
Model type: 	MDP (sparse)
States: 	907993
Transitions: 	1084752
Choices: 	1078873
Reward Models:  w_1_total
Labels: 	2
   * init -> 1 state(s)
   * ((((status = 7) & ((t1_r1 = 1) => ((((((m1_t1 = 1) & (1 = 1)) | ((m2_t1 = 1) & (2 = 1))) | ((m3_t1 = 1) & (3 = 1))) | ((m4_t1 = 1) & (1 = 1))) | ((m5_t1 = 1) & (2 = 1))))) & ((t1_r2 = 1) => ((((((m1_t1 = 1) & (1 = 2)) | ((m2_t1 = 1) & (2 = 2))) | ((m3_t1 = 1) & (3 = 2))) | ((m4_t1 = 1) & (1 = 2))) | ((m5_t1 = 1) & (2 = 2))))) & ((t1_r3 = 1) => ((((((m1_t1 = 1) & (1 = 3)) | ((m2_t1 = 1) & (2 = 3))) | ((m3_t1 = 1) & (3 = 3))) | ((m4_t1 = 1) & (1 = 3))) | ((m5_t1 = 1) & (2 = 3))))) -> 52200 state(s)
choice labels: 	no
Size in memory: 57802 kbytes
-------------------------------------------------------------- 

Model checking property: multi(Pmax=? [F ((((status = 7) & ((t1_r1 = 1) => ((((((m1_t1 = 1) & (1 = 1)) | ((m2_t1 = 1) & (2 = 1))) | ((m3_t1 = 1) & (3 = 1))) | ((m4_t1 = 1) & (1 = 1))) | ((m5_t1 = 1) & (2 = 1))))) & ((t1_r2 = 1) => ((((((m1_t1 = 1) & (1 = 2)) | ((m2_t1 = 1) & (2 = 2))) | ((m3_t1 = 1) & (3 = 2))) | ((m4_t1 = 1) & (1 = 2))) | ((m5_t1 = 1) & (2 = 2))))) & ((t1_r3 = 1) => ((((((m1_t1 = 1) & (1 = 3)) | ((m2_t1 = 1) & (2 = 3))) | ((m3_t1 = 1) & (3 = 3))) | ((m4_t1 = 1) & (1 = 3))) | ((m5_t1 = 1) & (2 = 3)))))], R[exp]{"w_1_total"}>=2.753061224 [C]) ...
---------------------------------------------------------------------------------------------------------------------------------------
                                                       Multi-objective Preprocessor Data                                               
---------------------------------------------------------------------------------------------------------------------------------------

Original Formula: 
--------------------------------------------------------------
	multi(Pmax=? [F ((((status = 7) & ((t1_r1 = 1) => ((((((m1_t1 = 1) & (1 = 1)) | ((m2_t1 = 1) & (2 = 1))) | ((m3_t1 = 1) & (3 = 1))) | ((m4_t1 = 1) & (1 = 1))) | ((m5_t1 = 1) & (2 = 1))))) & ((t1_r2 = 1) => ((((((m1_t1 = 1) & (1 = 2)) | ((m2_t1 = 1) & (2 = 2))) | ((m3_t1 = 1) & (3 = 2))) | ((m4_t1 = 1) & (1 = 2))) | ((m5_t1 = 1) & (2 = 2))))) & ((t1_r3 = 1) => ((((((m1_t1 = 1) & (1 = 3)) | ((m2_t1 = 1) & (2 = 3))) | ((m3_t1 = 1) & (3 = 3))) | ((m4_t1 = 1) & (1 = 3))) | ((m5_t1 = 1) & (2 = 3)))))], R[exp]{"w_1_total"}>=2.753061224 [C])

Objectives:
--------------------------------------------------------------
Pmax=? [F ((((status = 7) & ((t1_r1 = 1) => ((((((m1_t1 = 1) & (1 = 1)) | ((m2_t1 = 1) & (2 = 1))) | ((m3_t1 = 1) & (3 = 1))) | ((m4_t1 = 1) & (1 = 1))) | ((m5_t1 = 1) & (2 = 1))))) & ((t1_r2 = 1) => ((((((m1_t1 = 1) & (1 = 2)) | ((m2_t1 = 1) & (2 = 2))) | ((m3_t1 = 1) & (3 = 2))) | ((m4_t1 = 1) & (1 = 2))) | ((m5_t1 = 1) & (2 = 2))))) & ((t1_r3 = 1) => ((((((m1_t1 = 1) & (1 = 3)) | ((m2_t1 = 1) & (2 = 3))) | ((m3_t1 = 1) & (3 = 3))) | ((m4_t1 = 1) & (1 = 3))) | ((m5_t1 = 1) & (2 = 3)))))] 	(toOrigVal:  1*x +  0, 	intern threshold:   none, 	intern reward model: objective1 (positive), 	step bound: none)
R[exp]{"w_1_total"}>=2.75306 [C] 	(toOrigVal:  1*x +  0, 	intern threshold:>=2.753061224, 	intern reward model: objective2 (positive), 	step bound: none)
--------------------------------------------------------------

Original Model Information:
-------------------------------------------------------------- 
Model type: 	MDP (sparse)
States: 	907993
Transitions: 	1084752
Choices: 	1078873
Reward Models:  w_1_total
Labels: 	2
   * init -> 1 state(s)
   * ((((status = 7) & ((t1_r1 = 1) => ((((((m1_t1 = 1) & (1 = 1)) | ((m2_t1 = 1) & (2 = 1))) | ((m3_t1 = 1) & (3 = 1))) | ((m4_t1 = 1) & (1 = 1))) | ((m5_t1 = 1) & (2 = 1))))) & ((t1_r2 = 1) => ((((((m1_t1 = 1) & (1 = 2)) | ((m2_t1 = 1) & (2 = 2))) | ((m3_t1 = 1) & (3 = 2))) | ((m4_t1 = 1) & (1 = 2))) | ((m5_t1 = 1) & (2 = 2))))) & ((t1_r3 = 1) => ((((((m1_t1 = 1) & (1 = 3)) | ((m2_t1 = 1) & (2 = 3))) | ((m3_t1 = 1) & (3 = 3))) | ((m4_t1 = 1) & (1 = 3))) | ((m5_t1 = 1) & (2 = 3))))) -> 52200 state(s)
choice labels: 	no
Size in memory: 57802 kbytes
-------------------------------------------------------------- 

Preprocessed Model Information:
-------------------------------------------------------------- 
Model type: 	MDP (sparse)
States: 	907993
Transitions: 	1084752
Choices: 	1078873
Reward Models:  objective1, objective2
Labels: 	3
   * prob1 -> 0 state(s)
   * init -> 1 state(s)
   * ((((status = 7) & ((t1_r1 = 1) => ((((((m1_t1 = 1) & (1 = 1)) | ((m2_t1 = 1) & (2 = 1))) | ((m3_t1 = 1) & (3 = 1))) | ((m4_t1 = 1) & (1 = 1))) | ((m5_t1 = 1) & (2 = 1))))) & ((t1_r2 = 1) => ((((((m1_t1 = 1) & (1 = 2)) | ((m2_t1 = 1) & (2 = 2))) | ((m3_t1 = 1) & (3 = 2))) | ((m4_t1 = 1) & (1 = 2))) | ((m5_t1 = 1) & (2 = 2))))) & ((t1_r3 = 1) => ((((((m1_t1 = 1) & (1 = 3)) | ((m2_t1 = 1) & (2 = 3))) | ((m3_t1 = 1) & (3 = 3))) | ((m4_t1 = 1) & (1 = 3))) | ((m5_t1 = 1) & (2 = 3))))) -> 52200 state(s)
choice labels: 	no
Size in memory: 42568 kbytes
-------------------------------------------------------------- 

---------------------------------------------------------------------------------------------------------------------------------------

---------------------------------------------------------------------------------------------------------------------------------------
                                                 Multi-objective Model Checking Statistics:                                            
---------------------------------------------------------------------------------------------------------------------------------------

Runtimes (in seconds):
	 Preprocessing:    1249.116
	 Value Iterations:    0.788
	 Postprocessing:          0
	 Combined:         1249.918

Performed Refinement Steps: 1

---------------------------------------------------------------------------------------------------------------------------------------
 done.
Result (initial states): [false]
===== Statistics ==============================
peak memory usage: 451MB
CPU time: 516.276 seconds
===============================================
OVERALL_TIME; 1265.216
