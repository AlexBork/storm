SToRM
---------------

Version: 0.9.1 (+1781 commits) build from revision g5578a73 (DIRTY).

Linked with GNU Linear Programming Kit v4.57.
Linked with SMT-RAT 2.1.0.
Linked with CARL.
Command line arguments: -s team/team3obj_3.nm -prop team/team3obj_3_numerical.pctl --precision 0.000001 --multiobjective:precision 0.0001 
Current working directory: /Users/tim/storm/examples/multi-objective/mdp

-------------------------------------------------------------- 
Model type: 	MDP (sparse)
States: 	12475
Transitions: 	15228
Choices: 	14935
Reward Models:  w_1_total
Labels: 	3
   * ((((status = 5) & ((t2_r1 = 1) => ((((m1_t2 = 1) & (1 = 1)) | ((m2_t2 = 1) & (2 = 1))) | ((m3_t2 = 1) & (3 = 1))))) & ((t2_r2 = 1) => ((((m1_t2 = 1) & (1 = 2)) | ((m2_t2 = 1) & (2 = 2))) | ((m3_t2 = 1) & (3 = 2))))) & ((t2_r3 = 1) => ((((m1_t2 = 1) & (1 = 3)) | ((m2_t2 = 1) & (2 = 3))) | ((m3_t2 = 1) & (3 = 3))))) -> 546 state(s)
   * init -> 1 state(s)
   * ((((status = 5) & ((t1_r1 = 1) => ((((m1_t1 = 1) & (1 = 1)) | ((m2_t1 = 1) & (2 = 1))) | ((m3_t1 = 1) & (3 = 1))))) & ((t1_r2 = 1) => ((((m1_t1 = 1) & (1 = 2)) | ((m2_t1 = 1) & (2 = 2))) | ((m3_t1 = 1) & (3 = 2))))) & ((t1_r3 = 1) => ((((m1_t1 = 1) & (1 = 3)) | ((m2_t1 = 1) & (2 = 3))) | ((m3_t1 = 1) & (3 = 3))))) -> 546 state(s)
choice labels: 	no
Size in memory: 505 kbytes
-------------------------------------------------------------- 

Model checking property: multi(Pmax=? [F ((((status = 5) & ((t1_r1 = 1) => ((((m1_t1 = 1) & (1 = 1)) | ((m2_t1 = 1) & (2 = 1))) | ((m3_t1 = 1) & (3 = 1))))) & ((t1_r2 = 1) => ((((m1_t1 = 1) & (1 = 2)) | ((m2_t1 = 1) & (2 = 2))) | ((m3_t1 = 1) & (3 = 2))))) & ((t1_r3 = 1) => ((((m1_t1 = 1) & (1 = 3)) | ((m2_t1 = 1) & (2 = 3))) | ((m3_t1 = 1) & (3 = 3)))))], R[exp]{"w_1_total"}>=2.210204082 [C], P>=0.5 [F ((((status = 5) & ((t2_r1 = 1) => ((((m1_t2 = 1) & (1 = 1)) | ((m2_t2 = 1) & (2 = 1))) | ((m3_t2 = 1) & (3 = 1))))) & ((t2_r2 = 1) => ((((m1_t2 = 1) & (1 = 2)) | ((m2_t2 = 1) & (2 = 2))) | ((m3_t2 = 1) & (3 = 2))))) & ((t2_r3 = 1) => ((((m1_t2 = 1) & (1 = 3)) | ((m2_t2 = 1) & (2 = 3))) | ((m3_t2 = 1) & (3 = 3)))))]) ...
---------------------------------------------------------------------------------------------------------------------------------------
                                                       Multi-objective Preprocessor Data                                               
---------------------------------------------------------------------------------------------------------------------------------------

Original Formula: 
--------------------------------------------------------------
	multi(Pmax=? [F ((((status = 5) & ((t1_r1 = 1) => ((((m1_t1 = 1) & (1 = 1)) | ((m2_t1 = 1) & (2 = 1))) | ((m3_t1 = 1) & (3 = 1))))) & ((t1_r2 = 1) => ((((m1_t1 = 1) & (1 = 2)) | ((m2_t1 = 1) & (2 = 2))) | ((m3_t1 = 1) & (3 = 2))))) & ((t1_r3 = 1) => ((((m1_t1 = 1) & (1 = 3)) | ((m2_t1 = 1) & (2 = 3))) | ((m3_t1 = 1) & (3 = 3)))))], R[exp]{"w_1_total"}>=2.210204082 [C], P>=0.5 [F ((((status = 5) & ((t2_r1 = 1) => ((((m1_t2 = 1) & (1 = 1)) | ((m2_t2 = 1) & (2 = 1))) | ((m3_t2 = 1) & (3 = 1))))) & ((t2_r2 = 1) => ((((m1_t2 = 1) & (1 = 2)) | ((m2_t2 = 1) & (2 = 2))) | ((m3_t2 = 1) & (3 = 2))))) & ((t2_r3 = 1) => ((((m1_t2 = 1) & (1 = 3)) | ((m2_t2 = 1) & (2 = 3))) | ((m3_t2 = 1) & (3 = 3)))))])

Objectives:
--------------------------------------------------------------
Pmax=? [F ((((status = 5) & ((t1_r1 = 1) => ((((m1_t1 = 1) & (1 = 1)) | ((m2_t1 = 1) & (2 = 1))) | ((m3_t1 = 1) & (3 = 1))))) & ((t1_r2 = 1) => ((((m1_t1 = 1) & (1 = 2)) | ((m2_t1 = 1) & (2 = 2))) | ((m3_t1 = 1) & (3 = 2))))) & ((t1_r3 = 1) => ((((m1_t1 = 1) & (1 = 3)) | ((m2_t1 = 1) & (2 = 3))) | ((m3_t1 = 1) & (3 = 3)))))] 	(toOrigVal:  1*x +  0, 	intern threshold:   none, 	intern reward model: objective1 (positive), 	step bound: none)
R[exp]{"w_1_total"}>=2.2102 [C] 	(toOrigVal:  1*x +  0, 	intern threshold:>=2.210204082, 	intern reward model: objective2 (positive), 	step bound: none)
P>=0.5 [F ((((status = 5) & ((t2_r1 = 1) => ((((m1_t2 = 1) & (1 = 1)) | ((m2_t2 = 1) & (2 = 1))) | ((m3_t2 = 1) & (3 = 1))))) & ((t2_r2 = 1) => ((((m1_t2 = 1) & (1 = 2)) | ((m2_t2 = 1) & (2 = 2))) | ((m3_t2 = 1) & (3 = 2))))) & ((t2_r3 = 1) => ((((m1_t2 = 1) & (1 = 3)) | ((m2_t2 = 1) & (2 = 3))) | ((m3_t2 = 1) & (3 = 3)))))] 	(toOrigVal:  1*x +  0, 	intern threshold:>=  0.5, 	intern reward model: objective3 (positive), 	step bound: none)
--------------------------------------------------------------

Original Model Information:
-------------------------------------------------------------- 
Model type: 	MDP (sparse)
States: 	12475
Transitions: 	15228
Choices: 	14935
Reward Models:  w_1_total
Labels: 	3
   * ((((status = 5) & ((t2_r1 = 1) => ((((m1_t2 = 1) & (1 = 1)) | ((m2_t2 = 1) & (2 = 1))) | ((m3_t2 = 1) & (3 = 1))))) & ((t2_r2 = 1) => ((((m1_t2 = 1) & (1 = 2)) | ((m2_t2 = 1) & (2 = 2))) | ((m3_t2 = 1) & (3 = 2))))) & ((t2_r3 = 1) => ((((m1_t2 = 1) & (1 = 3)) | ((m2_t2 = 1) & (2 = 3))) | ((m3_t2 = 1) & (3 = 3))))) -> 546 state(s)
   * init -> 1 state(s)
   * ((((status = 5) & ((t1_r1 = 1) => ((((m1_t1 = 1) & (1 = 1)) | ((m2_t1 = 1) & (2 = 1))) | ((m3_t1 = 1) & (3 = 1))))) & ((t1_r2 = 1) => ((((m1_t1 = 1) & (1 = 2)) | ((m2_t1 = 1) & (2 = 2))) | ((m3_t1 = 1) & (3 = 2))))) & ((t1_r3 = 1) => ((((m1_t1 = 1) & (1 = 3)) | ((m2_t1 = 1) & (2 = 3))) | ((m3_t1 = 1) & (3 = 3))))) -> 546 state(s)
choice labels: 	no
Size in memory: 505 kbytes
-------------------------------------------------------------- 

Preprocessed Model Information:
-------------------------------------------------------------- 
Model type: 	MDP (sparse)
States: 	12475
Transitions: 	15228
Choices: 	14935
Reward Models:  objective3, objective2, objective1
Labels: 	4
   * ((((status = 5) & ((t2_r1 = 1) => ((((m1_t2 = 1) & (1 = 1)) | ((m2_t2 = 1) & (2 = 1))) | ((m3_t2 = 1) & (3 = 1))))) & ((t2_r2 = 1) => ((((m1_t2 = 1) & (1 = 2)) | ((m2_t2 = 1) & (2 = 2))) | ((m3_t2 = 1) & (3 = 2))))) & ((t2_r3 = 1) => ((((m1_t2 = 1) & (1 = 3)) | ((m2_t2 = 1) & (2 = 3))) | ((m3_t2 = 1) & (3 = 3))))) -> 546 state(s)
   * prob1 -> 0 state(s)
   * init -> 1 state(s)
   * ((((status = 5) & ((t1_r1 = 1) => ((((m1_t1 = 1) & (1 = 1)) | ((m2_t1 = 1) & (2 = 1))) | ((m3_t1 = 1) & (3 = 1))))) & ((t1_r2 = 1) => ((((m1_t1 = 1) & (1 = 2)) | ((m2_t1 = 1) & (2 = 2))) | ((m3_t1 = 1) & (3 = 2))))) & ((t1_r3 = 1) => ((((m1_t1 = 1) & (1 = 3)) | ((m2_t1 = 1) & (2 = 3))) | ((m3_t1 = 1) & (3 = 3))))) -> 546 state(s)
choice labels: 	no
Size in memory: 711 kbytes
-------------------------------------------------------------- 

---------------------------------------------------------------------------------------------------------------------------------------

---------------------------------------------------------------------------------------------------------------------------------------
                                                 Multi-objective Model Checking Statistics:                                            
---------------------------------------------------------------------------------------------------------------------------------------

Runtimes (in seconds):
	 Preprocessing:       0.065
	 Value Iterations:    0.062
	 Postprocessing:          0
	 Combined:            0.128

Performed Refinement Steps: 3

---------------------------------------------------------------------------------------------------------------------------------------
 done.
Result (initial states): [0.7448979592]
===== Statistics ==============================
peak memory usage: 201MB
CPU time: 0.337 seconds
===============================================
OVERALL_TIME; 0.415
